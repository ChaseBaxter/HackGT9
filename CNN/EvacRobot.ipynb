{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "b4Hv6Y4Lyz4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1147055-6ce2-43bd-8c81-c88449fc0e1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "from math import log2, sqrt\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2\n",
        "\n",
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import keras as ks\n",
        "from PIL import Image\n",
        "\n"
      ],
      "metadata": {
        "id": "1T1PjrBq2yiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773cea64-349c-41e2-b7c0-854506fabe80"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "init_lr= 0.006\n",
        "directory = '/content/gdrive/MyDrive/HackGT 9 Project/allpics'\n",
        "\n",
        "model = None\n",
        "def preprocess(img_dir, img_file):\n",
        "  img = tf.keras.utils.img_to_array(tf.keras.utils.load_img(img_dir + '/' + img_file))\n",
        "  img = img.astype(np.float32) - np.mean(img)\n",
        "  img /= np.std(img)\n",
        "  return img  \n",
        "\n",
        "def load_data(img_dir, num_classes):\n",
        "  goodnum = 0\n",
        "  imgs = []\n",
        "  labels = []\n",
        "  for img_file in listdir(img_dir):\n",
        "    img = preprocess(img_dir, img_file)\n",
        "    shape = np.shape(img)\n",
        "    if shape[1] < 112:\n",
        "      img = np.concatenate((img, np.zeros((112, 112 - shape[1], 3))), axis = 1)\n",
        "    if shape[0] < 112:\n",
        "      img = np.concatenate((img, np.zeros((112 - shape[0], 112, 3))), axis = 0)\n",
        "    goodnum = goodnum + 1\n",
        "    imgs.append(img)\n",
        "    label = int(img_file.split('_')[0])\n",
        "    labels.append(np.eye(num_classes)[label])\n",
        "  return imgs, labels\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "num_classes = 7\n",
        "imgs, labels = load_data(directory, num_classes)\n",
        "model.add(Conv2D(8, kernel_size=3, padding='same', input_shape = (112, 112, 3)))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(32, kernel_size=3, padding= 'same')) \n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(32, kernel_size=3, padding= 'same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Conv2D(64, kernel_size=3, padding= 'same'))\n",
        "model.add(LeakyReLU())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(7))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(len(imgs))\n",
        "model.fit(np.asarray(imgs), np.asarray(labels), epochs = 10, verbose = 0)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "open('object_recognition.tflite', 'wb').write(converter.convert())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "3PVdLLXVn4lW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f648c73e-af41-483a-a41c-c68c2402902f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51515152"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ip = tf.lite.Interpreter(model_path=\"object_recognition.tflite\")\n",
        "ip.allocate_tensors()\n",
        "input_index = ip.get_input_details()[0]['index']\n",
        "output_index = ip.get_output_details()[0]['index']\n",
        "\n",
        "def testnetwork(img_dir):\n",
        "  num_correct = 0\n",
        "  for img_file in listdir(img_dir):\n",
        "    img = preprocess(img_dir, img_file)\n",
        "    shape = np.shape(img)\n",
        "    if shape[1] < 112:\n",
        "      img = np.concatenate((img, np.zeros((112, 112 - shape[1], 3))), axis = 1)\n",
        "    if shape[0] < 112:\n",
        "      img = np.concatenate((img, np.zeros((112 - shape[0], 112, 3))), axis = 0)\n",
        "    ip.set_tensor(input_index, ([img.astype(np.float32)]))\n",
        "    ip.invoke()\n",
        "    preds = ip.get_tensor(output_index)\n",
        "    label = int(img_file.split('_')[0])\n",
        "    if np.argmax(preds) == label:\n",
        "      num_correct += 1\n",
        "    num_imgs = len(listdir(img_dir))\n",
        "  return('{} correct out of {}'.format(num_correct, num_imgs))\n",
        "\n",
        "print('Verifying the network on the dataset used to train it:')\n",
        "print(testnetwork('/content/gdrive/MyDrive/HackGT 9 Project/allpics'))\n",
        "print('Testing the network on a test dataset:')\n",
        "print(testnetwork('/content/gdrive/MyDrive/HackGT 9 Project/testpics'))"
      ],
      "metadata": {
        "id": "uMjJ40JZxdrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382a9740-7af9-4689-f061-02518feb3b08"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying the network on the dataset used to train it:\n",
            "486 correct out of 486\n",
            "Testing the network on a test dataset:\n",
            "11 correct out of 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZMitHM-CL2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}